import Groq from "groq-sdk";
import fs from "fs";

// Using Groq - free and fast API
let groq: Groq | null = null;

function getGroqClient(): Groq {
  if (!groq) {
    groq = new Groq({
      apiKey: process.env.GROQ_API_KEY || "placeholder",
    });
  }
  return groq;
}

/**
 * Check if Groq API key is configured
 */
export function isGroqConfigured(): boolean {
  return !!process.env.GROQ_API_KEY && process.env.GROQ_API_KEY !== "placeholder";
}

/**
 * Transcribe audio file using Groq Whisper
 */
export async function transcribeAudio(filePath: string): Promise<string> {
  if (!isGroqConfigured()) {
    // Return demo content if API key not configured (for testing)
    return "üìù Modo Demo: Para usar a transcri√ß√£o real, configure GROQ_API_KEY nas vari√°veis de ambiente.";
  }

  try {
    // Read file as buffer to ensure proper file format detection
    const audioBuffer = fs.readFileSync(filePath);
    const fileName = filePath.split('/').pop() || 'audio.ogg';
    
    const groq = getGroqClient();
    
    // Create a File-like object that Groq SDK can understand
    const audioFile = new File([audioBuffer], fileName, { type: 'audio/ogg' });
    
    const transcription = await groq.audio.transcriptions.create({
      file: audioFile as any,
      model: "whisper-large-v3",
      language: "pt",
      response_format: "json",
    });

    return transcription.text;
  } catch (error: any) {
    console.error("Erro na transcri√ß√£o:", error);
    throw new Error("Falha ao transcrever √°udio: " + error.message);
  }
}

/**
 * Extract text from image using Groq Llama Vision
 */
export async function extractTextFromImage(base64Image: string, mimeType: string = "image/jpeg"): Promise<string> {
  if (!isGroqConfigured()) {
    return "üì∏ Modo Demo: Para usar OCR real, configure GROQ_API_KEY nas vari√°veis de ambiente.";
  }

  try {
    const groq = getGroqClient();
    const completion = await groq.chat.completions.create({
      model: "llama-3.2-11b-vision-preview",
      messages: [
        {
          role: "user",
          content: [
            {
              type: "text",
              text: "Extraia TODO o texto desta imagem. Transcreva EXATAMENTE como est√° escrito, incluindo anota√ß√µes manuscritas, texto impresso, n√∫meros, s√≠mbolos. Mantenha a formata√ß√£o original. Se houver listas, mantenha-as. Se n√£o houver texto, responda 'Nenhum texto encontrado'.",
            },
            {
              type: "image_url",
              image_url: {
                url: `data:${mimeType};base64,${base64Image}`,
              },
            },
          ],
        },
      ],
      temperature: 0.1,
      max_tokens: 2048,
    });

    return completion.choices[0]?.message?.content || "Nenhum texto encontrado";
  } catch (error: any) {
    console.error("Erro no OCR:", error);
    throw new Error("Falha ao extrair texto: " + error.message);
  }
}

/**
 * Generate intelligent report from transcriptions and OCR results
 */
export async function generateIntelligentReport(
  audioTranscriptions: Array<{ name: string; content: string }>,
  ocrTexts: Array<{ name: string; content: string }>
): Promise<string> {
  if (!isGroqConfigured()) {
    return `RELAT√ìRIO DEMO - Trust AI\nData: ${new Date().toLocaleDateString('pt-BR')}\n\nPara gerar relat√≥rios completos, configure GROQ_API_KEY nas vari√°veis de ambiente.`;
  }

  try {
    const audioContent = audioTranscriptions
      .map((item, i) => `### √Åudio ${i + 1}: ${item.name}\n${item.content}`)
      .join("\n\n");

    const ocrContent = ocrTexts
      .map((item, i) => `### Documento ${i + 1}: ${item.name}\n${item.content}`)
      .join("\n\n");

    const prompt = `Voc√™ √© um assistente executivo especializado em an√°lise de conte√∫do e cria√ß√£o de relat√≥rios.

Analise o seguinte conte√∫do extra√≠do de √°udios e documentos manuscritos/impressos:

## √ÅUDIOS TRANSCRITOS:
${audioContent || "Nenhum √°udio fornecido."}

## DOCUMENTOS DIGITALIZADOS:
${ocrContent || "Nenhum documento fornecido."}

---

Crie um RELAT√ìRIO EXECUTIVO COMPLETO em portugu√™s (PT-BR) que inclua:

1. **RESUMO EXECUTIVO**: Resumo geral do conte√∫do analisado
2. **PRINCIPAIS PONTOS IDENTIFICADOS**: Liste os t√≥picos mais importantes mencionados
3. **TAREFAS E A√á√ïES NECESS√ÅRIAS**: Identifique a√ß√µes, pend√™ncias, decis√µes ou tarefas mencionadas
4. **AN√ÅLISE CRUZADA**: Se houver rela√ß√£o entre √°udios e documentos, destaque as conex√µes
5. **RECOMENDA√á√ïES**: Sugest√µes de pr√≥ximos passos baseadas no conte√∫do
6. **ITENS DE ATEN√á√ÉO**: Alertas, prazos ou quest√µes urgentes mencionadas

Seja espec√≠fico, objetivo e profissional. Use formata√ß√£o clara com t√≠tulos e listas.`;

    const groq = getGroqClient();
    const completion = await groq.chat.completions.create({
      model: "llama-3.3-70b-versatile",
      messages: [
        {
          role: "system",
          content: "Voc√™ √© um assistente executivo especializado em an√°lise de conte√∫do e cria√ß√£o de relat√≥rios profissionais.",
        },
        {
          role: "user",
          content: prompt,
        },
      ],
      temperature: 0.3,
      max_tokens: 4096,
    });

    return completion.choices[0]?.message?.content || "Erro ao gerar relat√≥rio.";
  } catch (error: any) {
    console.error("Erro ao gerar relat√≥rio:", error);
    throw new Error("Falha ao gerar relat√≥rio: " + error.message);
  }
}